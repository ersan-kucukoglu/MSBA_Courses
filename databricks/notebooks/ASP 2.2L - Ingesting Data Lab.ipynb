{"cells":[{"cell_type":"markdown","source":["-sandbox\n\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px\">\n</div>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"088fdf91-039e-4b82-b8e6-cb00522094c4"}}},{"cell_type":"markdown","source":["# Ingesting Data Lab\n\nRead in CSV files containing products data.\n\n##### Tasks\n1. Read with infer schema\n2. Read with user-defined schema\n3. Read with schema as DDL formatted string\n4. Write using Delta format"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"936fe59b-ec02-4b26-9d57-5d60a09d5508"}}},{"cell_type":"code","source":["%run ../Includes/Classroom-Setup"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"08a94c48-b364-4748-8cfc-3f433794c4bd"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### 1. Read with infer schema\n- View the first CSV file using DBUtils method **`fs.head`** with the filepath provided in the variable **`single_product_cs_fil_path`**\n- Create **`products_df`** by reading from CSV files located in the filepath provided in the variable **`products_csv_path`**\n  - Configure options to use first line as header and infer schema"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"75ac3154-45c4-4750-9674-ac6510896739"}}},{"cell_type":"code","source":["# ANSWER\nsingle_product_csv_file_path = f\"{datasets_dir}/products/products.csv/part-00000-tid-1663954264736839188-daf30e86-5967-4173-b9ae-d1481d3506db-2367-1-c000.csv\"\nprint(dbutils.fs.head(single_product_csv_file_path))\n\nproducts_csv_path = f\"{datasets_dir}/products/products.csv\"\nproducts_df = (spark\n               .read\n               .option(\"header\", True)\n               .option(\"inferSchema\", True)\n               .csv(products_csv_path)\n              )\n\nproducts_df.printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e215391e-ac6a-42d6-a0df-dc3f0394ca71"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["**1.1: CHECK YOUR WORK**"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"56573f98-717c-4d93-bb12-a0d15a105db9"}}},{"cell_type":"code","source":["assert(products_df.count() == 12)\nprint(\"All test pass\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3cbad2bf-72da-4e23-9a0f-63c91ad92b1d"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### 2. Read with user-defined schema\nDefine schema by creating a **`StructType`** with column names and data types"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"807ac573-1408-47ca-963f-5ff27d15dd25"}}},{"cell_type":"code","source":["# ANSWER\nfrom pyspark.sql.types import DoubleType, StringType, StructType, StructField\n\nuser_defined_schema = StructType([\n    StructField(\"item_id\", StringType(), True),\n    StructField(\"name\", StringType(), True),\n    StructField(\"price\", DoubleType(), True)\n])\n\nproducts_df2 = (spark\n                .read\n                .option(\"header\", True)\n                .schema(user_defined_schema)\n                .csv(products_csv_path)\n               )"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"81e1cc1c-3a4b-4f19-8997-61a45f04ffe6"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["**2.1: CHECK YOUR WORK**"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"36f2519e-a9bd-4828-8ac5-855f45566b53"}}},{"cell_type":"code","source":["assert(user_defined_schema.fieldNames() == [\"item_id\", \"name\", \"price\"])\nprint(\"All test pass\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"19d41d9c-d3d9-4be5-b6b1-f20af734f61f"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql import Row\n\nexpected1 = Row(item_id=\"M_STAN_Q\", name=\"Standard Queen Mattress\", price=1045.0)\nresult1 = products_df2.first()\n\nassert(expected1 == result1)\nprint(\"All test pass\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"db2317e9-2a87-40e8-9ba0-62bbeb667c41"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### 3. Read with DDL formatted string"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d8da8f39-4971-47e0-90bb-6c9e6eb61fac"}}},{"cell_type":"code","source":["# ANSWER\nddl_schema = \"`item_id` STRING,`name` STRING,`price` DOUBLE\"\n\nproducts_df3 = (spark\n                .read\n                .option(\"header\", True)\n                .schema(ddl_schema)\n                .csv(products_csv_path)\n               )"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d4333fc5-43a0-4725-a4e7-c5a252dc7145"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["**3.1: CHECK YOUR WORK**"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"472ba3d1-f01e-40f5-8179-7d4d9106c3e7"}}},{"cell_type":"code","source":["assert(products_df3.count() == 12)\nprint(\"All test pass\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"800c79ae-61ec-4689-b436-e1cd7019d0a5"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### 4. Write to Delta\nWrite **`products_df`** to the filepath provided in the variable **`products_output_path`**"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4c3fa52b-9ac2-4201-82b8-09648fb6875d"}}},{"cell_type":"code","source":["# ANSWER\nproducts_output_path = working_dir + \"/delta/products\"\n(products_df\n .write\n .format(\"delta\")\n .mode(\"overwrite\")\n .save(products_output_path)\n)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6c374163-66ef-4bc4-8fa1-41ae4988f3b9"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["**4.1: CHECK YOUR WORK**"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d5fabc32-9474-494d-9caf-86fe132eb163"}}},{"cell_type":"code","source":["verify_files = dbutils.fs.ls(products_output_path)\nverify_delta_format = False\nverify_num_data_files = 0\nfor f in verify_files:\n    if f.name == \"_delta_log/\":\n        verify_delta_format = True\n    elif f.name.endswith(\".parquet\"):\n        verify_num_data_files += 1\n\nassert verify_delta_format, \"Data not written in Delta format\"\nassert verify_num_data_files > 0, \"No data written\"\ndel verify_files, verify_delta_format, verify_num_data_files\nprint(\"All test pass\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"734bcc03-e9cb-4959-9491-3e9629ab71b3"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Clean up classroom"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"399a11c4-8302-4c06-92e1-f0f2b9b22b16"}}},{"cell_type":"code","source":["classroom_cleanup()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"390dd4e9-d4b3-4f0c-945c-121cce2937ae"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["-sandbox\n&copy; 2022 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"https://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"https://help.databricks.com/\">Support</a>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1d151644-ed07-4794-9f43-b95312aeb2c7"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"ASP 2.2L - Ingesting Data Lab","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":3745653733760839}},"nbformat":4,"nbformat_minor":0}
