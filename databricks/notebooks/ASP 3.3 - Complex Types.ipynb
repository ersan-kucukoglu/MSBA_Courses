{"cells":[{"cell_type":"markdown","source":["-sandbox\n\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px\">\n</div>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cf62eb77-3788-4a47-9b28-51da46f72eff"}}},{"cell_type":"markdown","source":["# Complex Types\n\nExplore built-in functions for working with collections and strings.\n\n##### Objectives\n1. Apply collection functions to process arrays\n1. Union DataFrames together\n\n##### Methods\n- <a href=\"https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.html\" target=\"_blank\">DataFrame</a>: **`unionByName`**\n- <a href=\"https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql.html?#functions\" target=\"_blank\">Built-In Functions</a>:\n  - Aggregate: **`collect_set`**\n  - Collection: **`array_contains`**, **`element_at`**, **`explode`**\n  - String: **`split`**"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ec7b1252-4edb-4f72-968d-5a428cffcd3d"}}},{"cell_type":"code","source":["%run ../Includes/Classroom-Setup"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3013eb6f-d9a8-4a24-8bc2-01e744816b8b"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.functions import *"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c33688c2-f76d-4a2f-9677-8425a9200ff7"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["df = spark.read.format(\"delta\").load(sales_path)\n\ndisplay(df)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"80172eb7-1d99-46c2-b58f-da03e16d5392"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# You will need this DataFrame for a later exercise\ndetails_df = (df\n              .withColumn(\"items\", explode(\"items\"))\n              .select(\"email\", \"items.item_name\")\n              .withColumn(\"details\", split(col(\"item_name\"), \" \"))\n             )\ndisplay(details_df)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e21e602a-19cd-4c4e-832d-9c21337c79d6"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### String Functions\nHere are some of the built-in functions available for manipulating strings.\n\n| Method | Description |\n| --- | --- |\n| translate | Translate any character in the src by a character in replaceString |\n| regexp_replace | Replace all substrings of the specified string value that match regexp with rep |\n| regexp_extract | Extract a specific group matched by a Java regex, from the specified string column |\n| ltrim | Removes the leading space characters from the specified string column |\n| lower | Converts a string column to lowercase |\n| split | Splits str around matches of the given pattern |"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"555fdf28-bd18-42c0-b47c-9180a7900ab1"}}},{"cell_type":"markdown","source":["For example: let's imagine that we need to parse our **`email`** column. We're going to use the **`split`** function  to split domain and handle."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9f6fd7eb-f0df-4d22-bd46-0064767c89a6"}}},{"cell_type":"code","source":["from pyspark.sql.functions import split"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"02b75b6f-0ea3-4905-9577-be854b9a645b"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["display(df.select(split(df.email, '@', 0).alias('email_handle')))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"94af67e2-f4b4-44bc-b132-96b9b6ddb5aa"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Collection Functions\n\nHere are some of the built-in functions available for working with arrays.\n\n| Method | Description |\n| --- | --- |\n| array_contains | Returns null if the array is null, true if the array contains value, and false otherwise. |\n| element_at | Returns element of array at given index. Array elements are numbered starting with **1**. |\n| explode | Creates a new row for each element in the given array or map column. |\n| collect_set | Returns a set of objects with duplicate elements eliminated. |"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bf9173bb-ad18-47dd-ae5c-9f311364c681"}}},{"cell_type":"code","source":["mattress_df = (details_df\n               .filter(array_contains(col(\"details\"), \"Mattress\"))\n               .withColumn(\"size\", element_at(col(\"details\"), 2)))\ndisplay(mattress_df)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9561670a-6269-4f1f-a913-ac5e06812eca"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Aggregate Functions\n\nHere are some of the built-in aggregate functions available for creating arrays, typically from GroupedData.\n\n| Method | Description |\n| --- | --- |\n| collect_list | Returns an array consisting of all values within the group. |\n| collect_set | Returns an array consisting of all unique values within the group. |"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b035129e-de13-449a-9490-66c820ff4f67"}}},{"cell_type":"markdown","source":["Let's say that we wanted to see the sizes of mattresses ordered by each email address. For this, we can use the **`collect_set`** function"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"38178179-74ee-4094-9f80-b60ff359de98"}}},{"cell_type":"code","source":["size_df = mattress_df.groupBy(\"email\").agg(collect_set(\"size\").alias(\"size options\"))\n\ndisplay(size_df)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c82ebb03-773b-47d8-a5f2-382b1b2a6572"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Clean up classroom\n\nAnd lastly, we'll clean up the classroom."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"292e9262-0283-49aa-b9ec-464329d25c37"}}},{"cell_type":"code","source":["classroom_cleanup()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a55ee767-0443-42a4-8bb7-8b0f4aeaaa3b"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["-sandbox\n&copy; 2022 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"https://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"https://help.databricks.com/\">Support</a>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fffc33da-87f7-4d82-aa37-5190e3edc385"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"ASP 3.3 - Complex Types","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":3745653733761486}},"nbformat":4,"nbformat_minor":0}
