{"cells":[{"cell_type":"markdown","source":["-sandbox\n\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px\">\n</div>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5f312284-0bcd-4793-8b20-99bfa21b0d3b"}}},{"cell_type":"markdown","source":["# Datetime Functions\n\n##### Objectives\n1. Cast to timestamp\n2. Format datetimes\n3. Extract from timestamp\n4. Convert to date\n5. Manipulate datetimes\n\n##### Methods\n- <a href=\"https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.Column.html#pyspark.sql.Column\" target=\"_blank\">Column</a>: **`cast`**\n- <a href=\"https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql.html?#functions\" target=\"_blank\">Built-In Functions</a>: **`date_format`**, **`to_date`**, **`date_add`**, **`year`**, **`month`**, **`dayofweek`**, **`minute`**, **`second`**"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7c67bec9-c96d-4c78-afbb-7a55676edfc7"}}},{"cell_type":"code","source":["%run ../Includes/Classroom-Setup"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"502c60c1-ce5a-42a9-912a-ca7f3bf5f27a"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Let's use a subset of the BedBricks events dataset to practice working with date times."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b0fb7f3d-fb1a-4061-8dbc-571506bd770a"}}},{"cell_type":"code","source":["from pyspark.sql.functions import col\n\ndf = spark.read.format(\"delta\").load(events_path).select(\"user_id\", col(\"event_timestamp\").alias(\"timestamp\"))\ndisplay(df)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7c4d3983-327d-4458-8126-570bed2eb12c"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Built-In Functions: Date Time Functions\nHere are a few built-in functions to manipulate dates and times in Spark.\n\n| Method | Description |\n| --- | --- |\n| **`add_months`** | Returns the date that is numMonths after startDate |\n| **`current_timestamp`** | Returns the current timestamp at the start of query evaluation as a timestamp column |\n| **`date_format`** | Converts a date/timestamp/string to a value of string in the format specified by the date format given by the second argument. |\n| **`dayofweek`** | Extracts the day of the month as an integer from a given date/timestamp/string |\n| **`from_unixtime`** | Converts the number of seconds from unix epoch (1970-01-01 00:00:00 UTC) to a string representing the timestamp of that moment in the current system time zone in the yyyy-MM-dd HH:mm:ss format |\n| **`minute`** | Extracts the minutes as an integer from a given date/timestamp/string. |\n| **`unix_timestamp`** | Converts time string with given pattern to Unix timestamp (in seconds) |"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2c139500-70ee-446c-ab55-1dddba345bcc"}}},{"cell_type":"markdown","source":["### Cast to Timestamp"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7939a543-bcb0-4f97-b967-cde2e8f22096"}}},{"cell_type":"markdown","source":["#### **`cast()`**\nCasts column to a different data type, specified using string representation or DataType."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"57086f2b-4f15-42d1-97c1-f9438911f206"}}},{"cell_type":"code","source":["timestamp_df = df.withColumn(\"timestamp\", (col(\"timestamp\") / 1e6).cast(\"timestamp\"))\ndisplay(timestamp_df)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a1ec5a1e-eb40-4aff-8f67-e98575f53ae8"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.types import TimestampType\n\ntimestamp_df = df.withColumn(\"timestamp\", (col(\"timestamp\") / 1e6).cast(TimestampType()))\ndisplay(timestamp_df)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0265cf21-56b7-43eb-b3ec-6a215cf8956e"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Datetime Patterns for Formatting and Parsing\nThere are several common scenarios for datetime usage in Spark:\n\n- CSV/JSON datasources use the pattern string for parsing and formatting datetime content.\n- Datetime functions related to convert StringType to/from DateType or TimestampType e.g. **`unix_timestamp`**, **`date_format`**, **`from_unixtime`**, **`to_date`**, **`to_timestamp`**, etc.\n\nSpark uses <a href=\"https://spark.apache.org/docs/latest/sql-ref-datetime-pattern.html\" target=\"_blank\">pattern letters for date and timestamp parsing and formatting</a>. A subset of these patterns are shown below.\n\n| Symbol | Meaning         | Presentation | Examples               |\n| ------ | --------------- | ------------ | ---------------------- |\n| G      | era             | text         | AD; Anno Domini        |\n| y      | year            | year         | 2020; 20               |\n| D      | day-of-year     | number(3)    | 189                    |\n| M/L    | month-of-year   | month        | 7; 07; Jul; July       |\n| d      | day-of-month    | number(3)    | 28                     |\n| Q/q    | quarter-of-year | number/text  | 3; 03; Q3; 3rd quarter |\n| E      | day-of-week     | text         | Tue; Tuesday           |\n\n<img src=\"https://files.training.databricks.com/images/icon_warn_32.png\" alt=\"Warning\"> Spark's handling of dates and timestamps changed in version 3.0, and the patterns used for parsing and formatting these values changed as well. For a discussion of these changes, please reference <a href=\"https://databricks.com/blog/2020/07/22/a-comprehensive-look-at-dates-and-timestamps-in-apache-spark-3-0.html\" target=\"_blank\">this Databricks blog post</a>."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4a9acce0-ccc7-4445-a66a-74661b5a359e"}}},{"cell_type":"markdown","source":["### Format date"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"37c69b5d-fd64-4eb6-9d45-42f00155bc9d"}}},{"cell_type":"markdown","source":["#### **`date_format()`**\nConverts a date/timestamp/string to a string formatted with the given date time pattern."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6c0d4710-5420-44cd-9adc-2358f4dbcd6f"}}},{"cell_type":"code","source":["from pyspark.sql.functions import date_format\n\nformatted_df = (timestamp_df\n                .withColumn(\"date string\", date_format(\"timestamp\", \"MMMM dd, yyyy\"))\n                .withColumn(\"time string\", date_format(\"timestamp\", \"HH:mm:ss.SSSSSS\"))\n               )\ndisplay(formatted_df)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0e88ee20-f4bb-4539-9a93-daabce0ed9ef"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Extract datetime attribute from timestamp"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"aa3a4d95-adcb-4488-8e02-dae99c63b35b"}}},{"cell_type":"markdown","source":["#### **`year`**\nExtracts the year as an integer from a given date/timestamp/string.\n\n##### Similar methods: **`month`**, **`dayofweek`**, **`minute`**, **`second`**, etc."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"88df33e8-2aa0-4eee-b29c-9bd0cda9c396"}}},{"cell_type":"code","source":["from pyspark.sql.functions import year, month, dayofweek, minute, second\n\ndatetime_df = (timestamp_df\n               .withColumn(\"year\", year(col(\"timestamp\")))\n               .withColumn(\"month\", month(col(\"timestamp\")))\n               .withColumn(\"dayofweek\", dayofweek(col(\"timestamp\")))\n               .withColumn(\"minute\", minute(col(\"timestamp\")))\n               .withColumn(\"second\", second(col(\"timestamp\")))\n              )\ndisplay(datetime_df)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1142eacc-b646-48aa-a133-86a08d90e466"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Convert to Date"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8be998f6-47b6-4fdc-bac5-505d2d7586e3"}}},{"cell_type":"markdown","source":["#### **`to_date`**\nConverts the column into DateType by casting rules to DateType."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"47a6ebeb-fda9-459d-a3cd-2d5a9590dab0"}}},{"cell_type":"code","source":["from pyspark.sql.functions import to_date\n\ndate_df = timestamp_df.withColumn(\"date\", to_date(col(\"timestamp\")))\ndisplay(date_df)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8eb66076-9c23-4dc5-877d-3477ce673e67"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Manipulate Datetimes"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e545e4b6-4dbf-42d9-b393-4286cf991fbb"}}},{"cell_type":"markdown","source":["#### **`date_add`**\nReturns the date that is the given number of days after start"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1785c46b-5f0a-412d-bd05-ae5f0cd4a409"}}},{"cell_type":"code","source":["from pyspark.sql.functions import date_add\n\nplus_2_df = timestamp_df.withColumn(\"plus_two_days\", date_add(col(\"timestamp\"), 2))\ndisplay(plus_2_df)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9e1f261b-b0f1-4ef8-8fcf-34210f6cd145"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Clean up classroom"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a1dd2c8e-371e-4443-9235-2cf56cd6a047"}}},{"cell_type":"code","source":["classroom_cleanup()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a60ce771-0e32-490a-8186-e1e3928aacb1"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["-sandbox\n&copy; 2022 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"https://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"https://help.databricks.com/\">Support</a>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5657e66c-d4aa-4560-b84b-8711606dfe17"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"ASP 3.2 - Datetimes","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":3745653733761592}},"nbformat":4,"nbformat_minor":0}
