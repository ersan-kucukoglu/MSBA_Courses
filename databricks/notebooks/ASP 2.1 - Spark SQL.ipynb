{"cells":[{"cell_type":"markdown","source":["-sandbox\n\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px\">\n</div>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1d1cf45a-e678-44f5-bf6d-a9336d17bda3"}}},{"cell_type":"markdown","source":["# Spark SQL\n\nDemonstrate fundamental concepts in Spark SQL using the DataFrame API.\n\n##### Objectives\n1. Run a SQL query\n1. Create a DataFrame from a table\n1. Write the same query using DataFrame transformations\n1. Trigger computation with DataFrame actions\n1. Convert between DataFrames and SQL\n\n##### Methods\n- <a href=\"https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql.html#spark-session-apis\" target=\"_blank\">SparkSession</a>: **`sql`**, **`table`**\n- <a href=\"https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.html\" target=\"_blank\">DataFrame</a>:\n  - Transformations:  **`select`**, **`where`**, **`orderBy`**\n  - Actions: **`show`**, **`count`**, **`take`**\n  - Other methods: **`printSchema`**, **`schema`**, **`createOrReplaceTempView`**"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"139490c5-c0b4-4c9e-8263-4063fa2ede28"}}},{"cell_type":"code","source":["%run ../Includes/Classroom-Setup-SQL"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1c88da44-22ce-4e0f-81b3-e8ca1164797c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Deleted the working directory dbfs:/user/kucukoglu_ersan@student.ceu.edu/dbacademy/aspwd/asp_2_1_spark_sql\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Deleted the working directory dbfs:/user/kucukoglu_ersan@student.ceu.edu/dbacademy/aspwd/asp_2_1_spark_sql\n"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Your working directory is\ndbfs:/user/kucukoglu_ersan@student.ceu.edu/dbacademy/aspwd\n\nThe source for this dataset is\nwasbs://courseware@dbacademy.blob.core.windows.net/apache-spark-programming-with-databricks/v02/\n\nSkipping install of existing dataset to\ndbfs:/user/kucukoglu_ersan@student.ceu.edu/dbacademy/aspwd/datasets\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Your working directory is\ndbfs:/user/kucukoglu_ersan@student.ceu.edu/dbacademy/aspwd\n\nThe source for this dataset is\nwasbs://courseware@dbacademy.blob.core.windows.net/apache-spark-programming-with-databricks/v02/\n\nSkipping install of existing dataset to\ndbfs:/user/kucukoglu_ersan@student.ceu.edu/dbacademy/aspwd/datasets\n"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[5]: DataFrame[key: string, value: string]","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[5]: DataFrame[key: string, value: string]"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":[""]}}],"execution_count":0},{"cell_type":"markdown","source":["## Multiple Interfaces\nSpark SQL is a module for structured data processing with multiple interfaces.\n\nWe can interact with Spark SQL in two ways:\n1. Executing SQL queries\n1. Working with the DataFrame API."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"49c74b7a-4759-443a-9888-b012b6a3420a"}}},{"cell_type":"markdown","source":["**Method 1: Executing SQL queries**\n\nThis is how we interacted with Spark SQL in the previous lesson."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7a65a787-97a0-43e3-a631-956ba61f9190"}}},{"cell_type":"code","source":["%sql\nSELECT name, price\nFROM products\nWHERE price < 200\nORDER BY price"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fdac2b84-1774-41b3-b8ae-ba0346772eeb"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["Standard Foam Pillow",59.0],["King Foam Pillow",79.0],["Standard Down Pillow",119.0],["King Down Pillow",159.0]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"name","type":"\"string\"","metadata":"{}"},{"name":"price","type":"\"double\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>name</th><th>price</th></tr></thead><tbody><tr><td>Standard Foam Pillow</td><td>59.0</td></tr><tr><td>King Foam Pillow</td><td>79.0</td></tr><tr><td>Standard Down Pillow</td><td>119.0</td></tr><tr><td>King Down Pillow</td><td>159.0</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["**Method 2: Working with the DataFrame API**\n\nWe can also express Spark SQL queries using the DataFrame API.\nThe following cell returns a DataFrame containing the same results as those retrieved above."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d526456d-75a6-4944-a662-6dc9a4c6c84c"}}},{"cell_type":"code","source":["display(spark\n        .table(\"products\")\n        .select(\"name\", \"price\")\n        .where(\"price < 200\")\n        .orderBy(\"price\")\n       )"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b5424aa2-3fe1-4221-b9d6-05baf251991e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["Standard Foam Pillow",59.0],["King Foam Pillow",79.0],["Standard Down Pillow",119.0],["King Down Pillow",159.0]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"name","type":"\"string\"","metadata":"{}"},{"name":"price","type":"\"double\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>name</th><th>price</th></tr></thead><tbody><tr><td>Standard Foam Pillow</td><td>59.0</td></tr><tr><td>King Foam Pillow</td><td>79.0</td></tr><tr><td>Standard Down Pillow</td><td>119.0</td></tr><tr><td>King Down Pillow</td><td>159.0</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["We'll go over the syntax for the DataFrame API later in the lesson, but you can see this builder design pattern allows us to chain a sequence of operations very similar to those we find in SQL."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e8c89a40-a76b-4cc6-9490-9471eb72aea6"}}},{"cell_type":"markdown","source":["## Query Execution\nWe can express the same query using any interface. The Spark SQL engine generates the same query plan used to optimize and execute on our Spark cluster.\n\n![query execution engine](https://files.training.databricks.com/images/aspwd/spark_sql_query_execution_engine.png)\n\n<img src=\"https://files.training.databricks.com/images/icon_note_32.png\" alt=\"Note\"> Resilient Distributed Datasets (RDDs) are the low-level representation of datasets processed by a Spark cluster. In early versions of Spark, you had to write <a href=\"https://spark.apache.org/docs/latest/rdd-programming-guide.html\" target=\"_blank\">code manipulating RDDs directly</a>. In modern versions of Spark you should instead use the higher-level DataFrame APIs, which Spark automatically compiles into low-level RDD operations."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7de938ce-e998-49d3-b614-6ec492ad9db5"}}},{"cell_type":"markdown","source":["## Spark API Documentation\n\nTo learn how we work with DataFrames in Spark SQL, let's first look at the Spark API documentation.\nThe main Spark <a href=\"https://spark.apache.org/docs/latest/\" target=\"_blank\">documentation</a> page includes links to API docs and helpful guides for each version of Spark.\n\nThe <a href=\"https://spark.apache.org/docs/latest/api/scala/org/apache/spark/index.html\" target=\"_blank\">Scala API</a> and <a href=\"https://spark.apache.org/docs/latest/api/python/index.html\" target=\"_blank\">Python API</a> are most commonly used, and it's often helpful to reference the documentation for both languages.\nScala docs tend to be more comprehensive, and Python docs tend to have more code examples.\n\n#### Navigating Docs for the Spark SQL Module\nFind the Spark SQL module by navigating to **`org.apache.spark.sql`** in the Scala API or **`pyspark.sql`** in the Python API.\nThe first class we'll explore in this module is the **`SparkSession`** class. You can find this by entering \"SparkSession\" in the search bar."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"522babfc-e5c2-4a1c-88ac-89361b16eb38"}}},{"cell_type":"markdown","source":["## SparkSession\nThe **`SparkSession`** class is the single entry point to all functionality in Spark using the DataFrame API.\n\nIn Databricks notebooks, the SparkSession is created for you, stored in a variable called **`spark`**."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b6441771-5c22-4335-beb6-d9f9f20c0f7d"}}},{"cell_type":"code","source":["spark"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"068ad632-c98b-402e-92df-5c1556299d37"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"/?o=309279391097570#setting/sparkui/0426-114259-39zztmxb/driver-11610893101326306\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.2.1</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[8]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Databricks Shell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        ","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"/?o=309279391097570#setting/sparkui/0426-114259-39zztmxb/driver-11610893101326306\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.2.1</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[8]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Databricks Shell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        "]}}],"execution_count":0},{"cell_type":"markdown","source":["The example from the beginning of this lesson used the SparkSession method **`table`** to create a DataFrame from the **`products`** table. Let's save this in the variable **`products_df`**."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"840a9553-9550-4cc0-9547-b91b946834f4"}}},{"cell_type":"code","source":["products_df = spark.table(\"products\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0c14460a-8369-4749-bb27-61b492e81ca5"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Below are several additional methods we can use to create DataFrames. All of these can be found in the <a href=\"https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.SparkSession.html\" target=\"_blank\">documentation</a> for **`SparkSession`**.\n\n#### **`SparkSession`** Methods\n| Method | Description |\n| --- | --- |\n| sql | Returns a DataFrame representing the result of the given query |\n| table | Returns the specified table as a DataFrame |\n| read | Returns a DataFrameReader that can be used to read data in as a DataFrame |\n| range | Create a DataFrame with a column containing elements in a range from start to end (exclusive) with step value and number of partitions |\n| createDataFrame | Creates a DataFrame from a list of tuples, primarily used for testing |"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fd7fe424-2ba5-4d83-b3a5-b2f844cad898"}}},{"cell_type":"markdown","source":["Let's use a SparkSession method to run SQL."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"84332fb7-450c-4168-8f97-f3f9742ec418"}}},{"cell_type":"code","source":["result_df = spark.sql(\"\"\"\nSELECT name, price\nFROM products\nWHERE price < 200\nORDER BY price\n\"\"\")\n\ndisplay(result_df)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5e630015-5788-4a4c-9080-d54755a61a3e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["Standard Foam Pillow",59.0],["King Foam Pillow",79.0],["Standard Down Pillow",119.0],["King Down Pillow",159.0]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"name","type":"\"string\"","metadata":"{}"},{"name":"price","type":"\"double\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>name</th><th>price</th></tr></thead><tbody><tr><td>Standard Foam Pillow</td><td>59.0</td></tr><tr><td>King Foam Pillow</td><td>79.0</td></tr><tr><td>Standard Down Pillow</td><td>119.0</td></tr><tr><td>King Down Pillow</td><td>159.0</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## DataFrames\nRecall that expressing our query using methods in the DataFrame API returns results in a DataFrame. Let's store this in the variable **`budget_df`**.\n\nA **DataFrame** is a distributed collection of data grouped into named columns."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0b438bfe-6e7c-4fea-926f-bb35b81f5dfe"}}},{"cell_type":"code","source":["budget_df = (spark\n             .table(\"products\")\n             .select(\"name\", \"price\")\n             .where(\"price < 200\")\n             .orderBy(\"price\")\n            )"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9ea4deb4-06a5-4d57-b2c5-cae891082623"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["We can use **`display()`** to output the results of a dataframe."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d15dc5b9-e81f-43b2-b966-29b3c1febe78"}}},{"cell_type":"code","source":["display(budget_df)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4707f51c-77cb-4ac7-bd08-630906ab6918"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["Standard Foam Pillow",59.0],["King Foam Pillow",79.0],["Standard Down Pillow",119.0],["King Down Pillow",159.0]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"name","type":"\"string\"","metadata":"{}"},{"name":"price","type":"\"double\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>name</th><th>price</th></tr></thead><tbody><tr><td>Standard Foam Pillow</td><td>59.0</td></tr><tr><td>King Foam Pillow</td><td>79.0</td></tr><tr><td>Standard Down Pillow</td><td>119.0</td></tr><tr><td>King Down Pillow</td><td>159.0</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["The **schema** defines the column names and types of a dataframe.\n\nAccess a dataframe's schema using the **`schema`** attribute."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"679f9194-fbd4-4471-a45b-52d21765df24"}}},{"cell_type":"code","source":["budget_df.schema"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dd9437e8-c48f-47b7-9749-c5213640792e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[13]: StructType(List(StructField(name,StringType,true),StructField(price,DoubleType,true)))","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[13]: StructType(List(StructField(name,StringType,true),StructField(price,DoubleType,true)))"]}}],"execution_count":0},{"cell_type":"markdown","source":["View a nicer output for this schema using the **`printSchema()`** method."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2d5f0121-4b58-4ea7-a8b3-86b2b35f3d53"}}},{"cell_type":"code","source":["budget_df.printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7c92f2c0-2a44-4562-8401-56f5d2f7cc6e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"root\n |-- name: string (nullable = true)\n |-- price: double (nullable = true)\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["root\n |-- name: string (nullable = true)\n |-- price: double (nullable = true)\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Transformations\nWhen we created **`budget_df`**, we used a series of DataFrame transformation methods e.g. **`select`**, **`where`**, **`orderBy`**.\n\n<strong><code>products_df  \n&nbsp;  .select(\"name\", \"price\")  \n&nbsp;  .where(\"price < 200\")  \n&nbsp;  .orderBy(\"price\")  \n</code></strong>\n    \nTransformations operate on and return DataFrames, allowing us to chain transformation methods together to construct new DataFrames.\nHowever, these operations can't execute on their own, as transformation methods are **lazily evaluated**.\n\nRunning the following cell does not trigger any computation."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f3a6fb6f-3844-4586-94c1-fc617199f3b7"}}},{"cell_type":"code","source":["(products_df\n  .select(\"name\", \"price\")\n  .where(\"price < 200\")\n  .orderBy(\"price\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1186afcb-2019-4c38-8008-362b9594bba5"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[16]: DataFrame[name: string, price: double]","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[16]: DataFrame[name: string, price: double]"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Actions\nConversely, DataFrame actions are methods that **trigger computation**.\nActions are needed to trigger the execution of any DataFrame transformations.\n\nThe **`show`** action causes the following cell to execute transformations."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1fb704e6-5d03-4b55-8b9f-ec0c051f0f73"}}},{"cell_type":"code","source":["(products_df\n  .select(\"name\", \"price\")\n  .where(\"price < 200\")\n  .orderBy(\"price\")\n  .show())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7481c174-3b7f-4c04-8c16-9d1341aeaad2"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+--------------------+-----+\n|                name|price|\n+--------------------+-----+\n|Standard Foam Pillow| 59.0|\n|    King Foam Pillow| 79.0|\n|Standard Down Pillow|119.0|\n|    King Down Pillow|159.0|\n+--------------------+-----+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+--------------------+-----+\n|                name|price|\n+--------------------+-----+\n|Standard Foam Pillow| 59.0|\n|    King Foam Pillow| 79.0|\n|Standard Down Pillow|119.0|\n|    King Down Pillow|159.0|\n+--------------------+-----+\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["Below are several examples of <a href=\"https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql.html#dataframe-apis\" target=\"_blank\">DataFrame</a> actions.\n\n### DataFrame Action Methods\n| Method | Description |\n| --- | --- |\n| show | Displays the top n rows of DataFrame in a tabular form |\n| count | Returns the number of rows in the DataFrame |\n| describe,  summary | Computes basic statistics for numeric and string columns |\n| first, head | Returns the the first row |\n| collect | Returns an array that contains all rows in this DataFrame |\n| take | Returns an array of the first n rows in the DataFrame |"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2210e58a-821d-4193-8afe-6d0542948c19"}}},{"cell_type":"markdown","source":["**`count`** returns the number of records in a DataFrame."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"62c1c8ae-2053-4b52-98d3-534a6a19d30a"}}},{"cell_type":"code","source":["budget_df.count()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"40fa9ef7-0244-459f-aeb3-0c815150f01b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[18]: 4","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[18]: 4"]}}],"execution_count":0},{"cell_type":"markdown","source":["**`collect`** returns an array of all rows in a DataFrame."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ca8a70bf-819f-4759-822c-dc2007588c01"}}},{"cell_type":"code","source":["budget_df.collect()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4fb67be4-ff18-46d1-83e0-71a740a864dd"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[19]: [Row(name='Standard Foam Pillow', price=59.0),\n Row(name='King Foam Pillow', price=79.0),\n Row(name='Standard Down Pillow', price=119.0),\n Row(name='King Down Pillow', price=159.0)]","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[19]: [Row(name='Standard Foam Pillow', price=59.0),\n Row(name='King Foam Pillow', price=79.0),\n Row(name='Standard Down Pillow', price=119.0),\n Row(name='King Down Pillow', price=159.0)]"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Convert between DataFrames and SQL"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"868eb7e2-202b-4aec-bb78-605f0faa64f5"}}},{"cell_type":"markdown","source":["**`createOrReplaceTempView`** creates a temporary view based on the DataFrame. The lifetime of the temporary view is tied to the SparkSession that was used to create the DataFrame."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b9b6f858-3b9e-4c83-b970-217edbb06a15"}}},{"cell_type":"code","source":["budget_df.createOrReplaceTempView(\"budget\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e5760c42-84b1-4d0d-8a51-79871e6c1745"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["display(spark.sql(\"SELECT * FROM budget\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"29e71128-638d-4ed0-983f-54e8308eb899"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Classroom Cleanup"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ed942d00-9f3d-4526-ba5f-da272a15f629"}}},{"cell_type":"code","source":["classroom_cleanup()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0bb39fe1-b3d9-4310-b400-8bd611277151"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["-sandbox\n&copy; 2022 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"https://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"https://help.databricks.com/\">Support</a>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"18126ee1-7d00-4a29-9280-57d787b365b3"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"ASP 2.1 - Spark SQL","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":3745653733761328}},"nbformat":4,"nbformat_minor":0}
