{"cells":[{"cell_type":"markdown","source":["-sandbox\n\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px\">\n</div>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"769479cd-6e62-47e1-aa7a-cf9e64bfb478"}}},{"cell_type":"markdown","source":["# Spark SQL Lab\n\n##### Tasks\n1. Create a DataFrame from the **`events`** table\n1. Display the DataFrame and inspect its schema\n1. Apply transformations to filter and sort **`macOS`** events\n1. Count results and take the first 5 rows\n1. Create the same DataFrame using a SQL query\n\n##### Methods\n- <a href=\"https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.SparkSession.html?highlight=sparksession\" target=\"_blank\">SparkSession</a>: **`sql`**, **`table`**\n- <a href=\"https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.html\" target=\"_blank\">DataFrame</a> transformations: **`select`**, **`where`**, **`orderBy`**\n- <a href=\"https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.html\" target=\"_blank\">DataFrame</a> actions: **`select`**, **`count`**, **`take`**\n- Other <a href=\"https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.html\" target=\"_blank\">DataFrame</a> methods: **`printSchema`**, **`schema`**, **`createOrReplaceTempView`**"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3984810f-5267-4508-bae6-62d26dbfa313"}}},{"cell_type":"code","source":["%run ../Includes/Classroom-Setup-SQL"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b4cd2d9c-50de-41f8-b361-416ca2ff962c"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### 1. Create a DataFrame from the **`events`** table\n- Use SparkSession to create a DataFrame from the **`events`** table"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5a5ced75-7cd8-4108-adee-a918f9142faf"}}},{"cell_type":"code","source":["# ANSWER\nevents_df = spark.table(\"events\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"90a07939-bd3f-406d-86ee-2cf34f0ebcb4"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### 2. Display DataFrame and inspect schema\n- Use methods above to inspect DataFrame contents and schema"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1d57514f-51b3-449e-a9c1-66f6592c6dc0"}}},{"cell_type":"code","source":["# ANSWER\ndisplay(events_df)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5b8089aa-3e57-4d36-8e7d-cac910c1e589"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# ANSWER\nevents_df.printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ab376843-ab83-452f-9606-aeb3fa0358a2"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### 3. Apply transformations to filter and sort **`macOS`** events\n- Filter for rows where **`device`** is **`macOS`**\n- Sort rows by **`event_timestamp`**\n\n<img src=\"https://files.training.databricks.com/images/icon_hint_32.png\" alt=\"Hint\"> Use single and double quotes in your filter SQL expression"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d26829f6-3eec-4eaa-b00c-3a6695b497f8"}}},{"cell_type":"code","source":["# ANSWER\nmac_df = (events_df\n          .where(\"device == 'macOS'\")\n          .sort(\"event_timestamp\")\n         )"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"adfd10ae-c90b-45ab-b25f-bbc8d01417c1"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### 4. Count results and take first 5 rows\n- Use DataFrame actions to count and take rows"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2efc9d9a-0e6e-419a-8eb6-543a9e5b10dc"}}},{"cell_type":"code","source":["# ANSWER\nnum_rows = mac_df.count()\nrows = mac_df.take(5)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5139dcbd-e523-4ae7-afb7-034cc5cdd3d0"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["**4.1: CHECK YOUR WORK**"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"85597cad-736d-4dd5-9576-2e12b87e827f"}}},{"cell_type":"code","source":["from pyspark.sql import Row\n\nassert(num_rows == 1938215)\nassert(len(rows) == 5)\nassert(type(rows[0]) == Row)\nprint(\"All test pass\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4c378e3c-cce5-46b4-bcb3-04570cdfd2f0"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### 5. Create the same DataFrame using SQL query\n- Use SparkSession to run a SQL query on the **`events`** table\n- Use SQL commands to write the same filter and sort query used earlier"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"96fabef5-f3a9-4c25-b1da-bebc95fe0ec5"}}},{"cell_type":"code","source":["# ANSWER\nmac_sql_df = spark.sql(\"\"\"\nSELECT *\nFROM events\nWHERE device = 'macOS'\nORDER By event_timestamp\n\"\"\")\n\ndisplay(mac_sql_df)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8fe111f9-a28f-47c9-921b-d7123390fad6"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["**5.1: CHECK YOUR WORK**\n- You should only see **`macOS`** values in the **`device`** column\n- The fifth row should be an event with timestamp **`1592539226602157`**"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"aa2e3a19-7ac5-43d6-a7d2-07d52078ecfb"}}},{"cell_type":"code","source":["verify_rows = mac_sql_df.take(5)\nassert (mac_sql_df.select(\"device\").distinct().count() == 1 and len(verify_rows) == 5 and verify_rows[0]['device'] == \"macOS\"), \"Incorrect filter condition\"\nassert (verify_rows[4]['event_timestamp'] == 1592539226602157), \"Incorrect sorting\"\ndel verify_rows\nprint(\"All test pass\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bdb8f036-d9ea-495f-8a71-e65682af0f13"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Classroom Cleanup"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fd3a8475-b778-468c-aa09-e6421ed664cb"}}},{"cell_type":"code","source":["classroom_cleanup()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f6868133-15ba-4263-87f3-e89780f2ce19"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["-sandbox\n&copy; 2022 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"https://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"https://help.databricks.com/\">Support</a>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6efae90f-3bd1-4d70-886a-0c1bd5cff3d7"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"ASP 2.1L - Spark SQL Lab","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":3745653733760863}},"nbformat":4,"nbformat_minor":0}
